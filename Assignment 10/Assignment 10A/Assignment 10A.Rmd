---
title: "Assignment 10A"
author: "James Chun"
date: "October 31, 2025"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Sentiment Analysis

## Primary Code Example
We will first incorporate the primary example code from **https://www.tidytextmining.com/sentiment.html** (Robinson) as it appears on the site. However, some edits have to be made to make the code functional in this markdown. As such, all such edits will be indicated with the comment "NEW".

### 2.1 The sentiments datasets
```{r}
library(textdata) #NEW

library(tidytext)

get_sentiments("afinn")
```

```{r}
get_sentiments("bing")
```

```{r}
get_sentiments("nrc")
```

### 2.2 Sentiment analysis with inner join

```{r message=FALSE}
library(janeaustenr)
library(dplyr)
library(stringr)

tidy_books <- austen_books() %>%
  group_by(book) %>%
  mutate(
    linenumber = row_number(),
    chapter = cumsum(str_detect(text, 
                                regex("^chapter [\\divxlc]", 
                                      ignore_case = TRUE)))) %>%
  ungroup() %>%
  unnest_tokens(word, text)
```

```{r}
nrc_joy <- get_sentiments("nrc") %>% 
  filter(sentiment == "joy")

tidy_books %>%
  filter(book == "Emma") %>%
  inner_join(nrc_joy) %>%
  count(word, sort = TRUE)
```

```{r message=FALSE, warning=FALSE}
library(tidyr)

jane_austen_sentiment <- tidy_books %>%
  inner_join(get_sentiments("bing")) %>%
  count(book, index = linenumber %/% 80, sentiment) %>%
  pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %>% 
  mutate(sentiment = positive - negative)
```

```{r}
library(ggplot2)

ggplot(jane_austen_sentiment, aes(index, sentiment, fill = book)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~book, ncol = 2, scales = "free_x")
```

### 2.3 Comparing the three sentiment dictionaries

```{r}
pride_prejudice <- tidy_books %>% 
  filter(book == "Pride & Prejudice")

pride_prejudice
```

```{r message=FALSE, warning=FALSE}
afinn <- pride_prejudice %>% 
  inner_join(get_sentiments("afinn")) %>% 
  group_by(index = linenumber %/% 80) %>% 
  summarise(sentiment = sum(value)) %>% 
  mutate(method = "AFINN")

bing_and_nrc <- bind_rows(
  pride_prejudice %>% 
    inner_join(get_sentiments("bing")) %>%
    mutate(method = "Bing et al."),
  pride_prejudice %>% 
    inner_join(get_sentiments("nrc") %>% 
                 filter(sentiment %in% c("positive", 
                                         "negative"))
    ) %>%
    mutate(method = "NRC")) %>%
  count(method, index = linenumber %/% 80, sentiment) %>%
  pivot_wider(names_from = sentiment,
              values_from = n,
              values_fill = 0) %>% 
  mutate(sentiment = positive - negative)
```

```{r}
bind_rows(afinn, 
          bing_and_nrc) %>%
  ggplot(aes(index, sentiment, fill = method)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~method, ncol = 1, scales = "free_y")
```

```{r}
get_sentiments("nrc") %>% 
  filter(sentiment %in% c("positive", "negative")) %>% 
  count(sentiment)
```

```{r}
get_sentiments("bing") %>% 
  count(sentiment)
```

### 2.4 Most common positive and negative words

```{r}
bing_word_counts <- tidy_books %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment, sort = TRUE) %>%
  ungroup()

bing_word_counts
```

```{r}
bing_word_counts %>%
  group_by(sentiment) %>%
  slice_max(n, n = 10) %>% 
  ungroup() %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(n, word, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~sentiment, scales = "free_y") +
  labs(x = "Contribution to sentiment",
       y = NULL)
```

```{r}
custom_stop_words <- bind_rows(tibble(word = c("miss"),  
                                      lexicon = c("custom")), 
                               stop_words)

custom_stop_words
```

### 2.5 Wordclouds

```{r message=FALSE, warning=FALSE}
library(wordcloud)

tidy_books %>%
  anti_join(stop_words) %>%
  count(word) %>%
  with(wordcloud(word, n, max.words = 100))
```

```{r message=FALSE, warning=FALSE}
library(reshape2)

tidy_books %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment, sort = TRUE) %>%
  acast(word ~ sentiment, value.var = "n", fill = 0) %>%
  comparison.cloud(colors = c("gray20", "gray80"),
                   max.words = 100)
```

### 2.6 Looking at units beyond just words

```{r}
p_and_p_sentences <- tibble(text = prideprejudice) %>% 
  unnest_tokens(sentence, text, token = "sentences")
```

```{r}
p_and_p_sentences$sentence[2]
```

```{r}
austen_chapters <- austen_books() %>%
  group_by(book) %>%
  unnest_tokens(chapter, text, token = "regex", 
                pattern = "Chapter|CHAPTER [\\dIVXLC]") %>%
  ungroup()

austen_chapters %>% 
  group_by(book) %>% 
  summarise(chapters = n())
```

```{r message=FALSE}
bingnegative <- get_sentiments("bing") %>% 
  filter(sentiment == "negative")

wordcounts <- tidy_books %>%
  group_by(book, chapter) %>%
  summarize(words = n())

tidy_books %>%
  semi_join(bingnegative) %>%
  group_by(book, chapter) %>%
  summarize(negativewords = n()) %>%
  left_join(wordcounts, by = c("book", "chapter")) %>%
  mutate(ratio = negativewords/words) %>%
  filter(chapter != 0) %>%
  slice_max(ratio, n = 1) %>% 
  ungroup()
```

## Code Extension
This extension intends to expand on the primary example code by applying the same concepts to a different corpus, whilst introducing an additional sentiment lexicon. 

### Load Libraries

```{r message=FALSE, warning=FALSE}
library(textdata)
library(dplyr)
library(gutenbergr)
library(tidyr)
library(ggplot2)
```

### Corpus and Sentiment Lexicon
We will be using the loughran sentiment lexicon. We will also be using literary works from Project Gutenberg accessed by the R package 'gutenbergr'. The specific works I'll be looking at will be the novels "Tom Sawyer" and "Huckleberry Finn" by Mark Twain.
<br>
<br>
First we'll import the necessary data and text.
```{r}
# Sentiment lexicon
loughran <- get_sentiments("loughran")

# Corpora
twain_ids <- gutenberg_works(author == "Twain, Mark") #only need to see the ids
twain_books <- gutenberg_download(c(74, 76))
```

### Tidy the novels

```{r warning=FALSE}
twain_books$book[twain_books$gutenberg_id == 74] <- "THE ADVENTURES OF TOM SAWYER"
twain_books$book[twain_books$gutenberg_id == 76] <- "ADVENTURES OF HUCKLEBERRY FINN"
twain_books$gutenberg_id <- NULL


twain_tidy_books <- twain_books %>%
  group_by(book) %>%
  mutate(
    linenumber = row_number(),
    chapter = cumsum(str_detect(text, 
                                regex("^chapter [\\divxlc]", 
                                      ignore_case = TRUE)))) %>%
  ungroup() %>%
  unnest_tokens(word, text)
```

### Sentiment Analysis
Perform sentiment analysis using the lexicon from 'loughran' on the two Twain novels.

```{r warning=FALSE, message=FALSE}
mark_twain_sentiment <- twain_tidy_books %>%
  inner_join(get_sentiments("loughran")) %>%
  count(book, index = linenumber %/% 80, sentiment) %>%
  pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %>% 
  mutate(sentiment = positive - negative)
```

Plot the results

```{r}
ggplot(mark_twain_sentiment, aes(index, sentiment, fill = book)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~book, ncol = 2, scales = "free_x")
```

### Lexicon Comparisons
Like the example code, we will be comparing Loughran to the lexicons AFINN, NFC, and bing. Also like the example code, we will focus on one novel: "Tom Sawyer".

```{r warning=FALSE, message=FALSE}
tom_sawyer <- twain_tidy_books %>% 
  filter(book == "THE ADVENTURES OF TOM SAWYER")

twain_afinn <- tom_sawyer %>% 
  inner_join(get_sentiments("afinn")) %>% 
  group_by(index = linenumber %/% 80) %>% 
  summarise(sentiment = sum(value)) %>% 
  mutate(method = "AFINN")

twain_bing_and_nrc <- bind_rows(
  tom_sawyer %>% 
    inner_join(get_sentiments("bing")) %>%
    mutate(method = "Bing et al."),
  tom_sawyer %>% 
    inner_join(get_sentiments("nrc") %>% 
                 filter(sentiment %in% c("positive", 
                                         "negative"))
    ) %>%
    mutate(method = "NRC")) %>%
  count(method, index = linenumber %/% 80, sentiment) %>%
  pivot_wider(names_from = sentiment,
              values_from = n,
              values_fill = 0) %>% 
  mutate(sentiment = positive - negative)

twain_loughran <- tom_sawyer %>%
  inner_join(get_sentiments("loughran")) %>%
  count(book, index = linenumber %/% 80, sentiment) %>%
  pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %>% 
  mutate(sentiment = positive - negative) %>%
  mutate(method = "Loughran")
```

Plot the results

```{r}
bind_rows(twain_afinn, 
          twain_bing_and_nrc, twain_loughran) %>%
  ggplot(aes(index, sentiment, fill = method)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~method, ncol = 1, scales = "free_y")
```

Most of the plots suggest that Tom Sawyer is a surprisingly negative book -- unless I am remembering it wrong. With that said, AFIN and NRC display the most positive outlook.  

## References

Robinson, J. S. and D. (n.d.). 2 sentiment analysis with Tidy Data: Text mining with R. A Tidy Approach. https://www.tidytextmining.com/sentiment.html 